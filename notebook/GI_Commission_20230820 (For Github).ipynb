{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dcd47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final code to be used\n",
    "\n",
    "import time\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from datetime import date\n",
    "\n",
    "folder_path = input(\"Please input the directory to the files -> /Users/jiayikoh/Downloads/07 GI Commission 3/\\n\")\n",
    "while os.path.isdir(folder_path) != True:\n",
    "    folder_path = input(\"Directory does not exist, please re-enter the directory to the files -> /Users/jiayikoh/Downloads/07 GI Commission 3/\\n\")\n",
    "os.chdir(folder_path)\n",
    "\n",
    "# read AIG comm statement\n",
    "\n",
    "file_pattern = '01*.xls*' \n",
    "\n",
    "matching_files = glob.glob(os.path.join(folder_path, file_pattern))\n",
    "\n",
    "aig_1 = pd.read_excel(matching_files[0], sheet_name='Commission_Final', skipfooter=1)\n",
    "aig_2 = pd.read_excel(matching_files[0], sheet_name='Sheet1', header=1, usecols=[1, 2], skipfooter=1)\n",
    "\n",
    "\n",
    "# name the GST Type column\n",
    "aig_2 = aig_2.rename(columns={'Unnamed: 2': 'GST Type'})\n",
    "\n",
    "# merge both dfs\n",
    "aig = pd.concat([aig_1, aig_2[['GST Type']]], axis=1)\n",
    "\n",
    "# remove \"IPPFA - \" from the ADVISER column (so that it could improve the FAR names matching algorithms)\n",
    "aig['ADVISER'] = aig['ADVISER'].str.replace('IPPFA - ', '')\n",
    "\n",
    "# rename the columns as per the working file\n",
    "columns = ['ADVISER', 'POLICY/ENDT', 'POLICY EFF DATE', 'DESCRIPTION/PARTICULARS', 'COMM AMT', 'GST ON COMM']\n",
    "\n",
    "rename_col = ['TFAR', 'Policy no.', 'Pol Date', 'Insured Name', 'Comm.Recd (with GST)', 'GST amt']\n",
    "\n",
    "label = dict(zip(columns, rename_col))\n",
    "\n",
    "aig = aig.rename(columns=label)\n",
    "\n",
    "# create \"Insurer\" column\n",
    "aig['Insurer'] = 'AIG-GI'\n",
    "\n",
    "# read AIA comm statement\n",
    "file_pattern = '03*.xls*' \n",
    "\n",
    "matching_files = glob.glob(os.path.join(folder_path, file_pattern))\n",
    "\n",
    "aia = pd.read_excel(matching_files[0], header=2, skipfooter=3)\n",
    "\n",
    "# forward fill the NaN with the previous valid observation\n",
    "aia = aia.fillna(method='ffill')\n",
    "\n",
    "# rename the columns as per the working file\n",
    "columns = ['TFAR Name', 'polno', 'Sum of TOTAL AMOUNT', 'Sum of GST']\n",
    "\n",
    "rename_col = ['TFAR', 'Policy no.', 'Comm.Recd (with GST)', 'GST amt']\n",
    "\n",
    "label = dict(zip(columns, rename_col))\n",
    "\n",
    "aia = aia.rename(columns=label)\n",
    "\n",
    "# create \"Insurer\" column\n",
    "aia['Insurer'] = 'AIA-GI'\n",
    "\n",
    "# Allianz Insurance commission statement\n",
    "file_pattern = '04*.xls*' \n",
    "\n",
    "matching_files = glob.glob(os.path.join(folder_path, file_pattern))\n",
    "\n",
    "allianz = pd.read_excel(matching_files[0], skipfooter=1)\n",
    "\n",
    "# rename the columns as per the working file\n",
    "columns = ['Policy Number', 'Agent Name', 'Effective Date', 'Total Commission', 'GST on Commission']\n",
    "\n",
    "rename_col = ['Policy no.', 'TFAR', 'Pol Date', 'Comm.Recd (with GST)', 'GST amt']\n",
    "\n",
    "label = dict(zip(columns, rename_col))\n",
    "\n",
    "allianz = allianz.rename(columns=label)\n",
    "\n",
    "# create \"Insurer\" column\n",
    "allianz['Insurer'] = 'ALLIANZ-GI'\n",
    "\n",
    "# Allied World commission statement\n",
    "allied = pd.read_excel('/Users/jiayikoh/Downloads/07 GI Commission 2/Allied World commission statement.xlsx', header=6, skipfooter=13)\n",
    "\n",
    "# remove NaN in Policy No.\n",
    "allied = allied.dropna(subset=['Commission'])\n",
    "\n",
    "# forward fill NaN\n",
    "allied.loc[:, ['Account No.', 'Account Name', 'Currency', 'Payable']] = allied.loc[:, ['Account No.', 'Account Name', 'Currency', 'Payable']].fillna(method='ffill')\n",
    "\n",
    "# remove 'Unnamed' columns\n",
    "allied = allied.loc[:, ~allied.columns.str.contains('Unnamed')]\n",
    "\n",
    "# rename the columns as per the working file\n",
    "columns = ['Policy No.', 'TFAR Name', 'Commission GST']\n",
    "\n",
    "rename_col = ['Policy no.', 'TFAR', 'GST amt']\n",
    "\n",
    "label = dict(zip(columns, rename_col))\n",
    "\n",
    "allied = allied.rename(columns=label)\n",
    "\n",
    "# create 'Insurer' column\n",
    "allied['Insurer'] = 'ALLIED WORLD-GI'\n",
    "allied['Comm.Recd (with GST)'] = allied[['Commission', 'GST amt']].sum(axis=1)*(-1)\n",
    "\n",
    "\n",
    "# Chubb commission statement\n",
    "file_pattern = '09*.xls*' \n",
    "\n",
    "matching_files = glob.glob(os.path.join(folder_path, file_pattern))\n",
    "\n",
    "chubb = pd.read_excel(matching_files[0], header=7, skipfooter=1)\n",
    "\n",
    "# remove 'Unnamed' columns\n",
    "chubb = chubb.loc[:, ~chubb.columns.str.contains('Unnamed')]\n",
    "\n",
    "# rename the columns as per the working file\n",
    "columns = ['Policy No.', 'Agent', 'Comm']\n",
    "\n",
    "rename_col = ['Policy no.', 'TFAR', 'Comm.Recd (with GST)']\n",
    "\n",
    "label = dict(zip(columns, rename_col))\n",
    "\n",
    "chubb = chubb.rename(columns=label)\n",
    "\n",
    "# create 'Insurer' column\n",
    "chubb['Insurer'] = 'CHUBB-GI'\n",
    "\n",
    "# FWD commission statement\n",
    "file_pattern = '15*.xls*' \n",
    "\n",
    "matching_files = glob.glob(os.path.join(folder_path, file_pattern))\n",
    "\n",
    "fwd_adviser = pd.read_excel(folder_path + 'FWD Adviser Codes List.xlsx')\n",
    "fwd = pd.read_excel(matching_files[0])\n",
    "\n",
    "fwd['agent_id_number'] = pd.to_numeric(fwd['agent_id_number'], errors='coerce')\n",
    "\n",
    "# merge with fwd advisor code list for the adviser details\n",
    "fwd = pd.merge(fwd, fwd_adviser, how='left', left_on='agent_id_number', right_on='FWD Life code')\n",
    "\n",
    "# rename the columns as per the working file\n",
    "columns = ['policy_number', 'GI Advisers', '$ txn commission', '$ txn gst commission']\n",
    "\n",
    "rename_col = ['Policy no.', 'TFAR', 'Comm.Recd (with GST)', 'GST amt']\n",
    "\n",
    "label = dict(zip(columns, rename_col))\n",
    "\n",
    "fwd = fwd.rename(columns=label)\n",
    "\n",
    "# create 'Insurer' column\n",
    "fwd['Insurer'] = 'FWD-GI'\n",
    "\n",
    "# Great Eastern commission statement\n",
    "file_pattern = '17*.xls*' \n",
    "\n",
    "matching_files = glob.glob(os.path.join(folder_path, file_pattern))\n",
    "\n",
    "ge = pd.read_excel(matching_files[0], sheet_name='MAY 23', skipfooter=2)\n",
    "\n",
    "# rename the columns as per the working file\n",
    "columns = ['Policy Number', 'Agent Name', 'Total Net Amount in Accounting Currency']\n",
    "\n",
    "rename_col = ['Policy no.', 'TFAR', 'Comm.Recd (with GST)']\n",
    "\n",
    "label = dict(zip(columns, rename_col))\n",
    "\n",
    "ge = ge.rename(columns=label)\n",
    "\n",
    "# create 'Insurer' column\n",
    "ge['Insurer'] = 'GE-GI'\n",
    "\n",
    "\n",
    "# HSBC commission statement\n",
    "file_pattern = '20_1*.xls*' \n",
    "\n",
    "matching_files = glob.glob(os.path.join(folder_path, file_pattern))\n",
    "\n",
    "hsbc_1 = pd.read_excel(matching_files[0], skipfooter=1)\n",
    "\n",
    "file_pattern = '20_2*.xls*' \n",
    "\n",
    "matching_files = glob.glob(os.path.join(folder_path, file_pattern))\n",
    "\n",
    "hsbc_2 = pd.read_excel(matching_files[0], sheet_name='Detailed Breakdown (Earned)', header=9, skipfooter=2)\n",
    "\n",
    "# rename the columns as per the working file\n",
    "columns = ['POLNUM', 'RIDESC', 'COMM_LCEAMT']\n",
    "\n",
    "rename_col = ['Policy no.', 'TFAR', 'Comm.Recd (with GST)']\n",
    "\n",
    "label = dict(zip(columns, rename_col))\n",
    "\n",
    "hsbc_1 = hsbc_1.rename(columns=label)\n",
    "\n",
    "# create 'Insurer' column\n",
    "hsbc_1['Insurer'] = 'HSBC-GI'\n",
    "\n",
    "\n",
    "# rename the columns as per the working file\n",
    "columns = ['Policy No.', 'Commission Amount']\n",
    "\n",
    "rename_col = ['Policy no.', 'Comm.Recd (with GST)']\n",
    "\n",
    "label = dict(zip(columns, rename_col))\n",
    "\n",
    "hsbc_2 = hsbc_2.rename(columns=label)\n",
    "\n",
    "# create 'Insurer' column\n",
    "hsbc_2['Insurer'] = 'HSBC-GI'\n",
    "\n",
    "hsbc = pd.concat([hsbc_1, hsbc_2])\n",
    "\n",
    "\n",
    "# Liberty commission statement\n",
    "file_pattern = '23*.csv*' \n",
    "\n",
    "matching_files = glob.glob(os.path.join(folder_path, file_pattern))\n",
    "\n",
    "liberty_adviser = pd.read_excel(folder_path + 'Liberty Adviser codes list.xlsx')\n",
    "liberty = pd.read_csv(matching_files[0])\n",
    "\n",
    "# merge with liberty adviser code list for the adviser details\n",
    "liberty = pd.merge(liberty, liberty_adviser, how='left', left_on='Sub Agent Code', right_on='CODE')\n",
    "\n",
    "# rename the columns as per the working file\n",
    "columns = ['Policy/Renewal/Endorsement', 'NAME OF ADVISER', 'Name of Insured', 'Total Commission Paid', 'Commission GST']\n",
    "\n",
    "rename_col = ['Policy no.', 'TFAR', 'Insured Name', 'Comm.Recd (with GST)', 'GST amt']\n",
    "\n",
    "label = dict(zip(columns, rename_col))\n",
    "\n",
    "liberty = liberty.rename(columns=label)\n",
    "\n",
    "# create 'Insurer' column\n",
    "liberty['Insurer'] = 'LIBERTY-GI'\n",
    "\n",
    "# MSIG commission statement\n",
    "\n",
    "file_pattern = '25*.xls*' \n",
    "\n",
    "matching_files = glob.glob(os.path.join(folder_path, file_pattern))\n",
    "\n",
    "msig = pd.read_excel(matching_files[0], header=32)\n",
    "msig_soa = pd.read_excel(folder_path + 'MSIG SOA.xlsx', header=7)\n",
    "\n",
    "# drop rows where all column values are NaN\n",
    "msig = msig.dropna(how='all')\n",
    "\n",
    "# drop columns where all row values are NaN\n",
    "msig = msig.dropna(how='all', axis=1)\n",
    "\n",
    "# filter without 'Settlement Date' and with 'Unnamed: 27' - commission amount\n",
    "msig = msig[(msig['Settlement Date'].isna()) & (msig['Unnamed: 27'].notna())]\n",
    "\n",
    "# merge commission statement and SOA\n",
    "msig = pd.merge(msig, msig_soa[['Name of FA Rep', 'Policy Number']], how='left', left_on='Policy No\\n', right_on='Policy Number')\n",
    "\n",
    "# rename the columns as per the working file\n",
    "columns = ['Policy No\\n', 'Name of FA Rep', 'Unnamed: 37', 'Unnamed: 33']\n",
    "\n",
    "rename_col = ['Policy no.', 'TFAR', 'Comm.Recd (with GST)', 'GST amt']\n",
    "\n",
    "label = dict(zip(columns, rename_col))\n",
    "\n",
    "msig = msig.rename(columns=label)\n",
    "\n",
    "# create 'Insurer' column\n",
    "msig['Insurer'] = 'MSIG-GI'\n",
    "\n",
    "\n",
    "# QBE commission statement\n",
    "\n",
    "file_pattern = '28*.xls*' \n",
    "\n",
    "matching_files = glob.glob(os.path.join(folder_path, file_pattern))\n",
    "\n",
    "qbe_adviser = pd.read_excel(folder_path + 'QBE-Qnect User List.xlsx')\n",
    "qbe = pd.read_excel(matching_files[0], skipfooter=1)\n",
    "\n",
    "# remove whitespace in the agent code\n",
    "qbe_adviser['P400_USER'] = qbe_adviser['P400_USER'].str.strip()\n",
    "\n",
    "# merge with QBE adviser code list to get adviser details\n",
    "qbe = pd.merge(qbe, qbe_adviser, how='left', left_on='REP_NAME', right_on='P400_USER')\n",
    "\n",
    "# rename the columns as per the working file\n",
    "columns = ['POLICY_NUMBER', 'Agent Name', 'COMMISSION_SGD', 'GST_ON_COMMISSION_SGD']\n",
    "\n",
    "rename_col = ['Policy no.', 'TFAR', 'Comm.Recd (with GST)', 'GST amt']\n",
    "\n",
    "label = dict(zip(columns, rename_col))\n",
    "\n",
    "qbe = qbe.rename(columns=label)\n",
    "\n",
    "# create 'Insurer' column\n",
    "qbe['Insurer'] = 'QBE-GI'\n",
    "\n",
    "\n",
    "# Singlife commission statement\n",
    "\n",
    "file_pattern = '30*.xls*' \n",
    "\n",
    "matching_files = glob.glob(os.path.join(folder_path, file_pattern))\n",
    "\n",
    "singlife = pd.read_excel(matching_files[0])\n",
    "\n",
    "# rename the columns as per the working file\n",
    "columns = ['POLNUM', 'SRVAGNAME', 'Total', 'GST on Commission']\n",
    "\n",
    "rename_col = ['Policy no.', 'TFAR', 'Comm.Recd (with GST)', 'GST amt']\n",
    "\n",
    "label = dict(zip(columns, rename_col))\n",
    "\n",
    "singlife = singlife.rename(columns=label)\n",
    "\n",
    "# create 'Insurer' column\n",
    "singlife['Insurer'] = 'SINGLIFE-GI'\n",
    "\n",
    "\n",
    "# Sompo commission statement\n",
    "file_pattern = '31*.xls*' \n",
    "\n",
    "matching_files = glob.glob(os.path.join(folder_path, file_pattern))\n",
    "\n",
    "sompo = pd.read_excel(matching_files[0])\n",
    "\n",
    "# remove columns with all the row values are NaN\n",
    "sompo = sompo.dropna(how='all', axis=1)\n",
    "\n",
    "# rename the columns as per the working file\n",
    "columns = ['Policy No.', 'Producer Name', 'Comm.', 'GST Comm.']\n",
    "\n",
    "rename_col = ['Policy no.', 'TFAR', 'Comm.Recd (with GST)', 'GST amt']\n",
    "\n",
    "label = dict(zip(columns, rename_col))\n",
    "\n",
    "sompo = sompo.rename(columns=label)\n",
    "\n",
    "# create 'Insurer' column\n",
    "sompo['Insurer'] = 'QBE-GI'\n",
    "\n",
    "\n",
    "# get the all the headers of the working file\n",
    "file_pattern = 'P0*.xls*' \n",
    "\n",
    "matching_files = glob.glob(os.path.join(folder_path, file_pattern))\n",
    "\n",
    "working_col = pd.read_excel(matching_files[0], sheet_name='Apr-23', header=3).columns\n",
    "\n",
    "# create an empty dataframe with the above column names\n",
    "wk_df = pd.DataFrame(columns=working_col).reset_index()\n",
    "\n",
    "# combine all processed commission statement df\n",
    "wk_df = pd.concat([aig, aia, allianz, allied, chubb, fwd, ge, liberty, qbe, singlife, sompo], ignore_index=True)\n",
    "\n",
    "# read the FAR masterlist\n",
    "far_master = pd.read_excel('FARs Masterlist 2023.xlsx', skiprows=1)\n",
    "\n",
    "# merge with itself to get the old agent's manager details\n",
    "far_master = pd.merge(far_master, far_master[['NEW FAR NAME', 'Manager', 'Mgr Rate']].rename(columns={'Manager':'Manager 2 Name', 'Mgr Rate':'Manager 2 GR%'}),\n",
    "                     how='left', left_on='FAR (Old)', right_on='NEW FAR NAME').rename(columns={'NEW FAR NAME_x':'NEW FAR NAME'})\n",
    "\n",
    "# read the revised name list\n",
    "revised_far_list = pd.read_excel('GI comm name matching.xls')\n",
    "\n",
    "# find the name in FAR masterlist using the revised name list provided by the name matching algorithm\n",
    "wk_df = pd.merge(wk_df, revised_far_list[['ADVISER', 'matched_name']], how='left', left_on='TFAR', right_on='ADVISER')\n",
    "\n",
    "# match the adviser details using the name matching list\n",
    "wk_df = pd.merge(wk_df, far_master[['NEW FAR NAME', 'Advisory Group', 2023, 'FAR Status']].rename(columns={2023:'GR%'}), how='left', left_on='matched_name', right_on='NEW FAR NAME')\n",
    "\n",
    "# load the e-submission list for the referrer list\n",
    "e_sub = pd.read_excel('GI e-submission list.xlsx')\n",
    "\n",
    "# match policy number to get referrer details\n",
    "wk_df = pd.merge(wk_df, e_sub[['Policy No', 'Name of Referral']].rename(columns={'Name of Referral':'Referrer'}), how='left', left_on='Policy no.', right_on='Policy No')\n",
    "\n",
    "# rename the columns as per the working file\n",
    "columns = ['TRANS CODE', 'ADVISER', 'POLICY/ENDT', 'POLICY EFF DATE', 'DESCRIPTION/PARTICULARS', 'COMM AMT', 'GST ON COMM']\n",
    "\n",
    "rename_col = ['Payment / Clawback', 'TFAR', 'Policy no.', 'Pol Date', 'Insured Name', 'Comm.Recd (with GST)', 'GST amt']\n",
    "\n",
    "# get the required fields \n",
    "columns = ['Policy no.', 'Insured Name', 'Insurer', 'TFAR', 'Referrer', 'Advisory Group', 'Comm.Recd (with GST)', 'GST amt', 'GR%']\n",
    "\n",
    "wk_df = wk_df.rename(columns={'Advisory Group_y':'Advisory Group'})[columns].drop_duplicates()\n",
    "\n",
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "writer = pd.ExcelWriter(f'S1 - Working {date.today():%Y/%m/%d}.xlsx')\n",
    "\n",
    "# # Write each dataframe to a different worksheet.\n",
    "wk_df.to_excel(writer, sheet_name='Data')\n",
    "#df_1_pivot.to_excel(writer, sheet_name='Pivot')\n",
    "\n",
    "# # Close the Pandas Excel writer and output the Excel file.\n",
    "writer.save()\n",
    "\n",
    "\n",
    "# get all the required fields from the first document\n",
    "file_pattern = 'P1*.xls*' \n",
    "\n",
    "matching_files = glob.glob(os.path.join(folder_path, file_pattern))\n",
    "\n",
    "df_1_col = pd.read_excel(matching_files[0], sheet_name='Data', skiprows=1).columns\n",
    "\n",
    "file_pattern = 'P0*.xls*' \n",
    "\n",
    "matching_files = glob.glob(os.path.join(folder_path, file_pattern))\n",
    "\n",
    "# use the working file df to extract the relevant information for \"1-Consolidated GI Com Month\"\n",
    "working_df = pd.read_excel(matching_files[0], sheet_name='Apr-23', header=3)\n",
    "\n",
    "# select the required fields\n",
    "df_1 = working_df[df_1_col]\n",
    "\n",
    "\n",
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "# writer = pd.ExcelWriter('1 - Consolidated GI Com May 2023.xls')\n",
    "writer = pd.ExcelWriter(f'S2 - 1 - Consolidated GI Com {date.today():%Y/%m/%d}.xlsx')\n",
    "\n",
    "# # Write each dataframe to a different worksheet.\n",
    "df_1.to_excel(writer, sheet_name='Data')\n",
    "# #df_1_pivot.to_excel(writer, sheet_name='Pivot')\n",
    "\n",
    "# # Close the Pandas Excel writer and output the Excel file.\n",
    "writer.save()\n",
    "\n",
    "\n",
    "\n",
    "file_pattern = 'P2*.xls*' \n",
    "\n",
    "matching_files = glob.glob(os.path.join(folder_path, file_pattern))\n",
    "\n",
    "df_2_col = pd.read_excel(matching_files, sheet_name='data', skiprows=1).columns\n",
    "\n",
    "# df_2 contains Paid only policies\n",
    "df_2 = working_df[working_df['Payment / Clawback'] == 'Paid']\n",
    "\n",
    "# rename columns to match the required format\n",
    "df_2 = df_2.rename(columns={'TFAR Name':'FAR Name', 'Total Paid':'Gross Revenue Received', 'GR%':\"FAR's GR% Entitlement\",\n",
    "                    'FAR Comm + Referral':'FAR Net Comm'})\n",
    "\n",
    "# create 'Type' column\n",
    "df_2['Type'] = 'General Insurance'\n",
    "\n",
    "# create columns for FAR Receiving Comm, Advisory Group2\n",
    "df_2['FAR Receiving Comm'] = df_2['FAR Name']\n",
    "df_2['Advisory Group2'] = df_2['Advisory Group']\n",
    "df_2[\"FAR's Status\"] = df_2['FAR Receiving Comm Status']\n",
    "\n",
    "# merge with FAR Masterlist to get the NRIC\n",
    "df_2 = pd.merge(df_2, far_master[['NEW FAR NAME', 'NRIC']], how='left', left_on='TFAR', right_on='NEW FAR NAME')\n",
    "\n",
    "# filter to get the required fields\n",
    "df_2 = df_2[df_2_col]\n",
    "\n",
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "# writer = pd.ExcelWriter('2 - FAR GI Comm Payout May 2023.xls')\n",
    "writer = pd.ExcelWriter(f'S3 - 2 - FAR GI Comm Payout {date.today():%Y/%m/%d}.xlsx')\n",
    "\n",
    "# # Write each dataframe to a different worksheet.\n",
    "df_2.to_excel(writer, sheet_name='Data')\n",
    "# #df_2_pivot.to_excel(writer, sheet_name='Pivot')\n",
    "\n",
    "# # Close the Pandas Excel writer and output the Excel file.\n",
    "writer.save()\n",
    "\n",
    "\n",
    "file_pattern = 'P3*.xls*' \n",
    "\n",
    "matching_files = glob.glob(os.path.join(folder_path, file_pattern))\n",
    "\n",
    "\n",
    "df_3_col = pd.read_excel(matching_files[0], header=2).columns\n",
    "\n",
    "df_3 = working_df.copy()\n",
    "\n",
    "# merge with FAR Masterlist to get manager details\n",
    "df_3 = pd.merge(df_3, far_master[['NEW FAR NAME', 'Manager', 'Mgr Rate', 'Manager 2 Name', 'Manager 2 GR%']].rename(columns={'Manager':'Manager Name', 'Mgr Rate':'Manager GR%'}), \n",
    "               how='left', left_on='TFAR', right_on='NEW FAR NAME')\n",
    "\n",
    "df_3 = df_3.rename(columns={'FAR Receiving Comm Status': 'FAR Status', }).drop_duplicates()\n",
    "\n",
    "df_3 = df_3.reindex(columns=df_3_col, fill_value=None)\n",
    "df_3['Manager AG'] = np.where(df_3['Manager Name'].isna(), np.nan, df_3['Advisory Group'])\n",
    "df_3['Manager 2 AG'] = np.where(df_3['Manager 2 Name'].isna(), np.nan, df_3['Advisory Group'])\n",
    "\n",
    "# # Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "# #writer = pd.ExcelWriter('3 - GI Overridding Split May 2023.xls')\n",
    "writer = pd.ExcelWriter(f'S4 - 3 - GI Overriding Split {date.today():%Y/%m/%d}.xlsx')\n",
    "\n",
    "# # Write each dataframe to a different worksheet.\n",
    "df_3.to_excel(writer, sheet_name='Data')\n",
    "\n",
    "# # Close the Pandas Excel writer and output the Excel file.\n",
    "writer.save()\n",
    "\n",
    "\n",
    "# this is for the GI GR file\n",
    "file_pattern = 'P4*.xls*' \n",
    "\n",
    "matching_files = glob.glob(os.path.join(folder_path, file_pattern))\n",
    "\n",
    "\n",
    "df_4_col = pd.read_excel(matching_files[0]).columns\n",
    "\n",
    "df_4 = df_2.rename(columns={'Pol #':'Policy No', 'Cash Book #':'Cash Book', 'Carrier':'Insurer', 'FAR Name':'TFAR',\n",
    "                           })\n",
    "\n",
    "df_4 = working_df.rename(columns={'Cashbook ref. no.':'Cash Book', 'Policy no.':'Policy No', 'Referrer':'REFERRAL',\n",
    "                                 'Advisory Group':'GROUP', 'Comm. Recd        (with GST)':'Comm W/O GST',\n",
    "                                 'GR%':'TFAR %', 'Amt':'TFAR Comm', '%.1':'Referrer %', 'Amt.1':'Referrer Comm'\n",
    "                                 })\n",
    "\n",
    "df_4['Adjustment'] = np.nan\n",
    "\n",
    "df_4 = df_4.reindex(columns=df_4_col, fill_value=None)\n",
    "\n",
    "# # Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "writer = pd.ExcelWriter(f'S5 - GI GR {date.today():%Y/%m/%d}.xlsx')\n",
    "\n",
    "# # Write each dataframe to a different worksheet.\n",
    "df_4.to_excel(writer, sheet_name='Data')\n",
    "# #df_2_pivot.to_excel(writer, sheet_name='Pivot')\n",
    "\n",
    "# # Close the Pandas Excel writer and output the Excel file.\n",
    "writer.save()\n",
    "\n",
    "\n",
    "# Record the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate and print the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Execution time: {elapsed_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a010fdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
